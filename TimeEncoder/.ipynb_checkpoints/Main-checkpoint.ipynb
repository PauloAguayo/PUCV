{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44311341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "#print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\n",
    "import os\n",
    "from support.utils import real_data_loading\n",
    "import pandas as pd\n",
    "from synthesizers.timeseries import TimeEncoder\n",
    "from synthesizers import ModelParameters\n",
    "from sklearn.decomposition import PCA#from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42d373",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c3d3a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_len = 24        # Timesteps\n",
    "n_seq = 8        # Features\n",
    "hidden_dim = 8     # Hidden units for generator (GRU & LSTM).\n",
    "                    # Also decides output_units for generator\n",
    "gamma = 1           # Used for discriminator loss\n",
    "noise_dim = 32      # Used by generator as a starter dimension\n",
    "dim = 128           # UNUSED\n",
    "batch_size = 8\n",
    "learning_rate = 5e-4\n",
    "beta_1 = 0          # UNUSED\n",
    "beta_2 = 1          # UNUSED\n",
    "data_dim = 28       # UNUSED\n",
    "\n",
    "gan_args = ModelParameters(batch_size=batch_size,\n",
    "                           lr=learning_rate,\n",
    "                           noise_dim=noise_dim,\n",
    "                           layers_dim=dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd56d5c8",
   "metadata": {},
   "source": [
    "# Input train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d14a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_path = \"data_train_24.csv\"\n",
    "train_df = pd.read_csv(train_path)\n",
    "\n",
    "\n",
    "# Data transformations to be applied prior to be used with the synthesizer model\n",
    "train_data = real_data_loading(train_df.values, seq_len=seq_len, n_signal=3)\n",
    "print(len(train_data))#, train_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f05db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data[:][0][0])\n",
    "#print(len(train_data[:][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cacae97",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3ad87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "synth = TimeEncoder(model_parameters=gan_args, hidden_dim=hidden_dim, seq_len=seq_len, n_seq=n_seq, gamma=1, n_out=1)\n",
    "synth.train(train_data, train_steps=500)\n",
    "\n",
    "folders = os.listdir('models')\n",
    "\n",
    "try:\n",
    "    n = np.max([int(f.split('_')[1]) for f in folders])\n",
    "    folder = os.path.join('models','model_'+str(n+1))\n",
    "    os.mkdir(folder)\n",
    "except:\n",
    "    folder = os.path.join('models','model_1')\n",
    "    os.mkdir(folder)\n",
    "\n",
    "print('Model saved in:',folder)\n",
    "synth.save(os.path.join(folder,'synth_energy.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join('models','model_1')\n",
    "os.mkdir(folder)\n",
    "\n",
    "print('Model saved in:',folder)\n",
    "#synth.save(os.path.join(folder,'synth_energy.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthesizers.nnn import make_keras_picklable\n",
    "from joblib import dump, load\n",
    "\n",
    "make_keras_picklable()\n",
    "dump(synth,os.path.join(folder,'synth_energy.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5158185",
   "metadata": {},
   "source": [
    "# Loading (in case you want to use a trained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60676f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = r'models\\model_12'\n",
    "synth = TimeEncoder.load(os.path.join(folder,'synth_energy.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a4301",
   "metadata": {},
   "source": [
    "# Input test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81774ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"data_test_24.csv\"\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Data transformations to be applied prior to be used with the synthesizer model\n",
    "test_data = real_data_loading(test_df.values, seq_len=seq_len)\n",
    "print(len(test_data), test_data[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ee545",
   "metadata": {},
   "source": [
    "# Synthetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a877d67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "synth_data = synth.sample(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f7e96f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['Open','High','Low','Close','Adj Close','Volume']\n",
    "\n",
    "#Plotting some generated samples. Both Synthetic and Original data are still standartized with values between [0,1]\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 10))\n",
    "axes=axes.flatten()\n",
    "\n",
    "time = list(range(1,25))\n",
    "obs = np.random.randint(len(energy_data))\n",
    "\n",
    "for j, col in enumerate(cols):\n",
    "    df = pd.DataFrame({'Real': test_data[obs][:, j],\n",
    "                   'Synthetic': synth_data[obs][:, j]})\n",
    "    df.plot(ax=axes[j],\n",
    "            title = col,\n",
    "            secondary_y='Synthetic data', style=['-', '--'])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055cce3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_size = 250\n",
    "idx = np.random.permutation(len(test_data))[:sample_size]\n",
    "\n",
    "real_sample = np.asarray(test_data)[idx]\n",
    "synthetic_sample = np.asarray(synth_data)[idx]\n",
    "\n",
    "# For the purpose of comparison we need the data to be 2-Dimensional.\n",
    "# For that reason we are going to use only two components for both the PCA and TSNE.\n",
    "# synth_data_reduced: {ndarray: (7000, 24)}\n",
    "# energy_data_reduced: {ndarray: (7000, 24)}\n",
    "synth_data_reduced = real_sample.reshape(-1, seq_len)\n",
    "energy_data_reduced = np.asarray(synthetic_sample).reshape(-1,seq_len)\n",
    "\n",
    "n_components = 2\n",
    "pca = PCA(n_components=n_components)\n",
    "tsne = TSNE(n_components=n_components, n_iter=300)\n",
    "\n",
    "# The fit of the methods must be done only using the real sequential data\n",
    "pca.fit(energy_data_reduced)\n",
    "\n",
    "# pca_real: {DataFrame: (7000, 2)}\n",
    "# pca_synth: {DataFrame: (7000, 2)}\n",
    "pca_real = pd.DataFrame(pca.transform(energy_data_reduced))\n",
    "pca_synth = pd.DataFrame(pca.transform(synth_data_reduced))\n",
    "\n",
    "# data_reduced: {ndarray: (14000, 24)}\n",
    "data_reduced = np.concatenate((energy_data_reduced, synth_data_reduced), axis=0)\n",
    "\n",
    "# tsne_results: {DataFrame: (14000, 2)}\n",
    "tsne_results = pd.DataFrame(tsne.fit_transform(data_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4227dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(20,10))\n",
    "spec = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)\n",
    "\n",
    "#TSNE scatter plot\n",
    "ax = fig.add_subplot(spec[0,0])\n",
    "ax.set_title('PCA results',\n",
    "             fontsize=20,\n",
    "             color='red',\n",
    "             pad=10)\n",
    "\n",
    "#PCA scatter plot\n",
    "plt.scatter(pca_real.iloc[:, 0].values, pca_real.iloc[:,1].values,\n",
    "            c='black', alpha=0.2, label='Original')\n",
    "plt.scatter(pca_synth.iloc[:,0], pca_synth.iloc[:,1],\n",
    "            c='red', alpha=0.2, label='Synthetic')\n",
    "ax.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(spec[0,1])\n",
    "ax2.set_title('TSNE results',\n",
    "              fontsize=20,\n",
    "              color='red',\n",
    "              pad=10)\n",
    "\n",
    "plt.scatter(tsne_results.iloc[:sample_size, 0].values, tsne_results.iloc[:sample_size,1].values,\n",
    "            c='black', alpha=0.2, label='Original')\n",
    "plt.scatter(tsne_results.iloc[sample_size:,0], tsne_results.iloc[sample_size:,1],\n",
    "            c='red', alpha=0.2, label='Synthetic')\n",
    "\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('Validating synthetic vs real data diversity and distributions',\n",
    "             fontsize=16,\n",
    "             color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "\n",
    "#First implement a simple RNN model for prediction\n",
    "def RNN_regression(units):\n",
    "    opt = Adam(name='AdamOpt')\n",
    "    loss = MeanAbsoluteError(name='MAE')\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=units,\n",
    "                  name=f'RNN_1'))\n",
    "    model.add(Dense(units=10,\n",
    "                    activation='sigmoid',\n",
    "                    name='OUT'))\n",
    "    model.compile(optimizer=opt, loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the dataset for the regression model\n",
    "stock_data=np.asarray(test_data)\n",
    "#synth_data = synth_data[:len(stock_data)]\n",
    "n_events = len(stock_data)\n",
    "\n",
    "#Split data on train and test\n",
    "idx = np.arange(n_events)\n",
    "n_train = int(.75*n_events)\n",
    "train_idx = idx[:n_train]\n",
    "test_idx = idx[n_train:]\n",
    "\n",
    "#Define the X for synthetic and real data\n",
    "X_stock_train = stock_data[train_idx, :seq_len, :]\n",
    "X_synth_train = synth_data[train_idx, :seq_len, :]\n",
    "\n",
    "X_stock_test = stock_data[test_idx, :seq_len, :]\n",
    "y_stock_test = stock_data[test_idx, -1, :]\n",
    "\n",
    "#Define the y for synthetic and real datasets\n",
    "y_stock_train = stock_data[train_idx, -1, :]\n",
    "y_synth_train = synth_data[train_idx, -1, :]\n",
    "\n",
    "print('Synthetic X train: {}'.format(X_synth_train.shape))\n",
    "print('Real X train: {}'.format(X_stock_train.shape))\n",
    "\n",
    "print('Synthetic y train: {}'.format(y_synth_train.shape))\n",
    "print('Real y train: {}'.format(y_stock_train.shape))\n",
    "\n",
    "print('Real X test: {}'.format(X_stock_test.shape))\n",
    "print('Real y test: {}'.format(y_stock_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c871881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model with the real train data\n",
    "ts_real = RNN_regression(12)\n",
    "early_stopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "real_train = ts_real.fit(x=X_stock_train,\n",
    "                          y=y_stock_train,\n",
    "                          validation_data=(X_stock_test, y_stock_test),\n",
    "                          epochs=200,\n",
    "                          batch_size=128,\n",
    "                          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f3a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model with the synthetic data\n",
    "ts_synth = RNN_regression(12)\n",
    "synth_train = ts_synth.fit(x=X_synth_train,\n",
    "                          y=y_synth_train,\n",
    "                          validation_data=(X_stock_test, y_stock_test),\n",
    "                          epochs=200,\n",
    "                          batch_size=128,\n",
    "                          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f03ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize the metrics here as a pandas dataframe\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_log_error\n",
    "real_predictions = ts_real.predict(X_stock_test)\n",
    "synth_predictions = ts_synth.predict(X_stock_test)\n",
    "\n",
    "metrics_dict = {'r2': [r2_score(y_stock_test, real_predictions),\n",
    "                       r2_score(y_stock_test, synth_predictions)],\n",
    "                'MAE': [mean_absolute_error(y_stock_test, real_predictions),\n",
    "                        mean_absolute_error(y_stock_test, synth_predictions)],\n",
    "                'MRLE': [mean_squared_log_error(y_stock_test, real_predictions),\n",
    "                         mean_squared_log_error(y_stock_test, synth_predictions)]}\n",
    "\n",
    "results = pd.DataFrame(metrics_dict, index=['Real', 'Synthetic'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b9524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
