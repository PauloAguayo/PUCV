{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bac061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import function, GradientTape, sqrt, abs, reduce_mean, ones_like, zeros_like, convert_to_tensor, float32, config, reshape\n",
    "from tensorflow import data as tfdata\n",
    "from tensorflow import nn\n",
    "from keras import (Model, Sequential, Input)\n",
    "from keras.layers import (GRU, LSTM, Dense, Flatten)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import (BinaryCrossentropy, MeanSquaredError)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "import os\n",
    "from support.utils import real_data_loading\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA#from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a42a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_data(data, batch_size):\n",
    "        data = convert_to_tensor(data, dtype=float32)\n",
    "        return iter(tfdata.Dataset.from_tensor_slices(data)\n",
    "                                .batch(batch_size).repeat(1))\n",
    "    \n",
    "def order_batch(data, ind):\n",
    "        d = []\n",
    "        for i in data:\n",
    "            d.append(i[ind])\n",
    "        return(d)\n",
    "    \n",
    "def make_net(model, n_layers, hidden_units, output_units, net_type='GRU'):\n",
    "    if net_type=='GRU':\n",
    "        for i in range(n_layers):\n",
    "            model.add(GRU(units=hidden_units,\n",
    "                      return_sequences=True,\n",
    "                      name=f'GRU_{i + 1}'))\n",
    "    else:\n",
    "        for i in range(n_layers):\n",
    "            model.add(LSTM(units=hidden_units,\n",
    "                      return_sequences=True,\n",
    "                      name=f'LSTM_{i + 1}'))\n",
    "    if output_units==1:\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(units=output_units,\n",
    "                        activation='sigmoid',\n",
    "                        name='OUT'))\n",
    "        return(model)\n",
    "\n",
    "    model.add(Dense(units=output_units,\n",
    "                    activation='sigmoid',\n",
    "                    name='OUT'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb47761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6619902840\n",
      "1686491944\n",
      "3902591\n"
     ]
    }
   ],
   "source": [
    "train_path = \"data_train_24.csv\"\n",
    "train_df = pd.read_csv(train_path)\n",
    "\n",
    "test_path = \"data_test_24.csv\"\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "seq_len = 24\n",
    "\n",
    "# Data transformations to be applied prior to be used with the synthesizer model\n",
    "train_data = real_data_loading(train_df.values, seq_len=seq_len, n_signal=3)\n",
    "test_data = real_data_loading(test_df.values, seq_len=seq_len, n_signal=3)\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0b10e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recovery(Model):\n",
    "    def __init__(self, hidden_dim, n_out, n_layers):#, net_type):\n",
    "        super(Recovery, self).__init__()\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.n_out=n_out\n",
    "        #self.net_type=net_type\n",
    "        self.n_layers=n_layers\n",
    "    \n",
    "    def call(self,x):\n",
    "        y = Sequential(name='Recovery')(x)\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            y = GRU(units=self.hidden_dim, return_sequences=True, name=f'GRU_{i + 1}')(y)\n",
    "            \n",
    "        y = Flatten()(y)\n",
    "\n",
    "        return(Dense(units=self.n_out, activation='sigmoid', name='OUT')(y))\n",
    "        \n",
    "class Embedder(Model):\n",
    "    def __init__(self, hidden_dim, n_layers):\n",
    "        super(Embedder, self).__init__()\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.n_layers=n_layers\n",
    "    \n",
    "    def call(self,x):\n",
    "        y = Sequential(name='Embedder')(x)\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            y = GRU(units=self.hidden_dim, return_sequences=True, name=f'GRU_{i + 1}')(y)\n",
    "\n",
    "        return(Dense(units=self.hidden_dim, activation='sigmoid', name='OUT')(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85a51989",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = n_seq = 8\n",
    "n_out = 1\n",
    "batch_size = 16\n",
    "recovery = Recovery(hidden_dim, n_out, 3)\n",
    "embedder = Embedder(hidden_dim, 3)\n",
    "\n",
    "X = Input(shape=[seq_len, n_seq], name='RealData') #, batch_size=batch_size\n",
    "\n",
    "#--------------------------------\n",
    "# Building the AutoEncoder\n",
    "#--------------------------------\n",
    "H = embedder(X)\n",
    "X_tilde = recovery(H)\n",
    "\n",
    "autoencoder = Model(inputs=X, outputs=X_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e89fa4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = MeanSquaredError()\n",
    "\n",
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc752288",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.MeanSquaredError(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.MeanSquaredError(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16fbbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = autoencoder(inputs)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, autoencoder.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, autoencoder.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62f36125",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, labels):\n",
    "  predictions = autoencoder(inputs)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822208f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Network training:   0%|                                                                          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "#for epoch in range(EPOCHS):\n",
    "for epoch in tqdm(range(EPOCHS), desc='Network training'):\n",
    "    for images, labels in zip([next(get_batch_data(order_batch(train_data,0), batch_size))], [next(get_batch_data(order_batch(train_data,1), batch_size))]):\n",
    "        train_step(images, labels)\n",
    "\n",
    "    for test_images, test_labels in zip([next(get_batch_data(order_batch(test_data,0), batch_size))], [next(get_batch_data(order_batch(test_data,1), batch_size))]):\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    template = 'Epoch {}, Perdida: {}, Exactitud: {}, Perdida de prueba: {}, Exactitud de prueba: {}'\n",
    "    print(template.format(epoch+1,\n",
    "                        train_loss.result(),\n",
    "                        train_accuracy.result()*100,\n",
    "                        test_loss.result(),\n",
    "                        test_accuracy.result()*100))\n",
    "\n",
    "    # Reinicia las metricas para el siguiente epoch.\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455ab85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
